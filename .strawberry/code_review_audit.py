#!/usr/bin/env python3
"""
ä»£ç å®¡æŸ¥å¹»è§‰æ£€æµ‹è„šæœ¬

é›†æˆ pythea çš„ audit_trace_budget åŠŸèƒ½ï¼Œç”¨äºæ£€æµ‹ AI ä»£ç åˆ†æä¸­çš„å¹»è§‰ã€‚
"""

import json
import os
import sys
from pathlib import Path

# æ·»åŠ  pythea è·¯å¾„
sys.path.insert(0, '/Users/aaxis/code/AAXIS/pythea/strawberry/src')

from strawberry.trace_budget import score_trace_budget
from strawberry.backend import BackendConfig
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
import subprocess


@dataclass
class Span:
    sid: str
    text: str


@dataclass
class Step:
    idx: int
    claim: str
    cites: List[str]
    confidence: float


@dataclass
class Trace:
    steps: List[Step]
    spans: List[Span]


def extract_code_claims(file_path: str) -> tuple[List[Dict], List[Dict]]:
    """
    ä»ä»£ç æ–‡ä»¶ä¸­æå–å£°æ˜å’Œè¯æ®

    Returns:
        (steps, spans) - å¯ä»¥ç”¨äº audit_trace_budget çš„æ•°æ®
    """
    with open(file_path, 'r') as f:
        content = f.read()

    steps = []
    spans = []
    span_idx = 0

    lines = content.split('\n')

    for idx, line in enumerate(lines, 1):
        # è·³è¿‡ç©ºè¡Œå’Œçº¯æ³¨é‡Š
        if not line.strip() or line.strip().startswith('//'):
            continue

        # æå–ä»£ç ç‰¹å¾ä½œä¸ºè¯æ®
        if 'import' in line:
            spans.append({
                "sid": f"S{span_idx}",
                "text": f"Line {idx}: {line.strip()}"
            })
            steps.append({
                "idx": len(steps),
                "claim": f"å¯¼å…¥ä¾èµ–: {line.strip()}",
                "cites": [f"S{span_idx}"],
                "confidence": 0.95
            })
            span_idx += 1

        elif 'function' in line or 'const' in line or 'let' in line or 'var' in line:
            spans.append({
                "sid": f"S{span_idx}",
                "text": f"Line {idx}: {line.strip()}"
            })
            steps.append({
                "idx": len(steps),
                "claim": f"å£°æ˜: {line.strip()[:60]}...",
                "cites": [f"S{span_idx}"],
                "confidence": 0.95
            })
            span_idx += 1

        elif 'export' in line:
            spans.append({
                "sid": f"S{span_idx}",
                "text": f"Line {idx}: {line.strip()}"
            })
            steps.append({
                "idx": len(steps),
                "claim": f"å¯¼å‡º: {line.strip()[:60]}...",
                "cites": [f"S{span_idx}"],
                "confidence": 0.95
            })
            span_idx += 1

    return steps, spans


def run_code_audit(
    file_paths: List[str],
    verifier_model: str = "openai/gpt-4o-mini",
    backend_url: Optional[str] = None,
    api_key: Optional[str] = None
) -> Dict[str, Any]:
    """
    å¯¹ä»£ç æ–‡ä»¶è¿è¡Œå¹»è§‰æ£€æµ‹å®¡è®¡

    Args:
        file_paths: è¦å®¡æŸ¥çš„æ–‡ä»¶åˆ—è¡¨
        verifier_model: éªŒè¯æ¨¡å‹
        backend_url: åç«¯ API URL (å¦‚ OpenRouter)
        api_key: API å¯†é’¥

    Returns:
        å®¡è®¡ç»“æœå­—å…¸
    """
    all_steps = []
    all_spans = []
    file_results = []

    # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„å£°æ˜å’Œè¯æ®
    for file_path in file_paths:
        if not os.path.exists(file_path):
            continue

        steps, spans = extract_code_claims(file_path)

        # é‡æ–°ç¼–å· spans é¿å…å†²çª
        span_offset = len(all_spans)
        span_id_map = {}

        for i, span in enumerate(spans):
            new_sid = f"S{span_offset + i}"
            span_id_map[span['sid']] = new_sid
            all_spans.append({
                "sid": new_sid,
                "text": span['text']
            })

        for step in steps:
            # æ›´æ–°å¼•ç”¨çš„ span ID
            new_cites = [span_id_map.get(c, c) for c in step['cites']]
            all_steps.append({
                "idx": len(all_steps),
                "claim": f"{file_path}: {step['claim']}",
                "cites": new_cites,
                "confidence": step['confidence']
            })

    if not all_steps:
        return {
            "flagged": False,
            "total_steps": 0,
            "flagged_steps": 0,
            "details": [],
            "message": "æ²¡æœ‰å¯å®¡è®¡çš„ä»£ç "
        }

    # åˆ›å»º trace å¯¹è±¡
    spans_obj = [Span(**s) for s in all_spans]
    steps_obj = [Step(**s) for s in all_steps]
    trace = Trace(steps=steps_obj, spans=spans_obj)

    # é…ç½®åç«¯
    cfg = BackendConfig(
        kind="openai",
        base_url=backend_url or os.environ.get("OPENAI_BASE_URL"),
        api_key=api_key or os.environ.get("OPENAI_API_KEY"),
        max_concurrency=4,
        timeout_s=30.0,
    )

    # è¿è¡Œå®¡è®¡
    try:
        results = score_trace_budget(
            trace=trace,
            verifier_model=verifier_model,
            backend_cfg=cfg,
            default_target=0.9,
            temperature=0.0,
            top_logprobs=10,
            placeholder="[REDACTED]"
        )

        flagged_count = 0
        details = []

        for r in results:
            gap = r.budget_gap_min
            is_flagged = gap > 2.0

            if is_flagged:
                flagged_count += 1

            details.append({
                "idx": r.idx,
                "claim": r.claim,
                "cites": r.cites,
                "budget_gap": {
                    "min": gap,
                    "max": r.budget_gap_max,
                    "units": "bits"
                },
                "flagged": is_flagged,
                "status": "âš ï¸ éœ€å®¡æŸ¥" if gap > 2 else "âœ… å¯ä¿¡" if gap < 0 else "ğŸŸ¡ å¯æ¥å—"
            })

        return {
            "flagged": flagged_count > 0,
            "total_steps": len(results),
            "flagged_steps": flagged_count,
            "details": details,
            "message": f"æ£€æµ‹äº† {len(results)} ä¸ªä»£ç å£°æ˜ï¼Œ{flagged_count} ä¸ªè¢«æ ‡è®°"
        }

    except Exception as e:
        return {
            "flagged": True,
            "total_steps": len(all_steps),
            "flagged_steps": 0,
            "details": [],
            "error": str(e),
            "message": f"å®¡è®¡å¤±è´¥: {e}"
        }


def main():
    """ä¸»å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='ä»£ç å®¡æŸ¥å¹»è§‰æ£€æµ‹')
    parser.add_argument('--files', nargs='+', required=True, help='è¦å®¡æŸ¥çš„æ–‡ä»¶åˆ—è¡¨')
    parser.add_argument('--model', default='openai/gpt-4o-mini', help='éªŒè¯æ¨¡å‹')
    parser.add_argument('--backend-url', help='åç«¯ API URL')
    parser.add_argument('--api-key', help='API å¯†é’¥')
    parser.add_argument('--output', required=True, help='è¾“å‡º JSON æ–‡ä»¶')

    args = parser.parse_args()

    result = run_code_audit(
        file_paths=args.files,
        verifier_model=args.model,
        backend_url=args.backend_url,
        api_key=args.api_key
    )

    with open(args.output, 'w') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(f"âœ“ å®¡è®¡å®Œæˆï¼Œç»“æœä¿å­˜åˆ° {args.output}")
    print(result['message'])


if __name__ == '__main__':
    main()
